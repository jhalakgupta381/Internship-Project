{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4c879f-4742-47ce-86e1-6dad4bbf6143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping 5 second(s)...\n",
      "Sleeping 4 second(s)...\n",
      "Sleeping 3 second(s)...\n",
      "Sleeping 2 second(s)...\n",
      "Sleeping 1 second(s)...\n",
      "Finished in 5.01 second(s)\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "\n",
    "def do_something(seconds):\n",
    "    print(f'Sleeping {seconds} second(s)...')\n",
    "    #time.sleep(seconds)\n",
    "    return f'Done Sleeping...{seconds}'\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    secs = [5, 4, 3, 2, 1]\n",
    "    results = executor.map(do_something, secs)\n",
    "\n",
    "finish = time.perf_counter()\n",
    "\n",
    "print(f'Finished in {round(finish-start, 2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad75e7b-225a-45df-b0bf-cd75e0a1293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photo-1507143550189-fed454f93097.jpg was downloaded...\n",
      "photo-1513938709626-033611b8cc03.jpg was downloaded...\n",
      "photo-1516117172878-fd2c41f4a759.jpg was downloaded...\n",
      "photo-1516972810927-80185027ca84.jpg was downloaded...\n",
      "photo-1532009324734-20a7a5813719.jpg was downloaded...\n",
      "photo-1550439062-609e1531270e.jpg was downloaded...\n",
      "photo-1541698444083-023c97d3f4b6.jpg was downloaded...\n",
      "photo-1549692520-acc6669e2f0c.jpg was downloaded...\n",
      "photo-1522364723953-452d3431c267.jpg was downloaded...\n",
      "photo-1524429656589-6633a470097c.jpg was downloaded...\n",
      "photo-1564135624576-c5c88640f235.jpg was downloaded...\n",
      "photo-1530224264768-7ff8c1789d79.jpg was downloaded...\n",
      "photo-1530122037265-a5f1f91d3b99.jpg was downloaded...\n",
      "photo-1504198453319-5ce911bafcde.jpg was downloaded...\n",
      "photo-1493976040374-85c8e12f0c0e.jpg was downloaded...\n",
      "Finished in 43.111335000023246 seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import concurrent.futures\n",
    "\n",
    "img_urls = [\n",
    "    'https://images.unsplash.com/photo-1516117172878-fd2c41f4a759',\n",
    "    'https://images.unsplash.com/photo-1532009324734-20a7a5813719',\n",
    "    'https://images.unsplash.com/photo-1524429656589-6633a470097c',\n",
    "    'https://images.unsplash.com/photo-1530224264768-7ff8c1789d79',\n",
    "    'https://images.unsplash.com/photo-1564135624576-c5c88640f235',\n",
    "    'https://images.unsplash.com/photo-1541698444083-023c97d3f4b6',\n",
    "    'https://images.unsplash.com/photo-1522364723953-452d3431c267',\n",
    "    'https://images.unsplash.com/photo-1513938709626-033611b8cc03',\n",
    "    'https://images.unsplash.com/photo-1507143550189-fed454f93097',\n",
    "    'https://images.unsplash.com/photo-1493976040374-85c8e12f0c0e',\n",
    "    'https://images.unsplash.com/photo-1504198453319-5ce911bafcde',\n",
    "    'https://images.unsplash.com/photo-1530122037265-a5f1f91d3b99',\n",
    "    'https://images.unsplash.com/photo-1516972810927-80185027ca84',\n",
    "    'https://images.unsplash.com/photo-1550439062-609e1531270e',\n",
    "    'https://images.unsplash.com/photo-1549692520-acc6669e2f0c'\n",
    "]\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "\n",
    "def download_image(img_url):\n",
    "    img_bytes = requests.get(img_url).content\n",
    "    img_name = img_url.split('/')[3]\n",
    "    img_name = f'{img_name}.jpg'\n",
    "    with open(img_name, 'wb') as img_file:\n",
    "        img_file.write(img_bytes)\n",
    "        print(f'{img_name} was downloaded...')\n",
    "\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    executor.map(download_image, img_urls)\n",
    "\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f'Finished in {t2-t1} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a2a3ef-e6b9-4429-9421-7811db55f2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: Starting\n",
      "Task 2: Starting\n",
      "Task 3: Starting\n",
      "Task 4: Starting\n",
      "Task 5: Starting\n",
      "Task 6: Starting\n",
      "Filtered Data Summary (Cumulative_cases > 0):\n",
      "            Date      Country  Cumulative_cases\n",
      "47    2020-03-09      Albania                 2\n",
      "48    2020-03-10      Albania                10\n",
      "49    2020-03-11      Albania                12\n",
      "50    2020-03-12      Albania                23\n",
      "51    2020-03-13      Albania                33\n",
      "...          ...          ...               ...\n",
      "27659 2020-01-31        China               211\n",
      "27666 2020-01-31        Italy                 2\n",
      "27669 2020-01-31        China               120\n",
      "27670 2020-03-31  Afghanistan               196\n",
      "27671 2020-03-31  Afghanistan               196\n",
      "\n",
      "[12048 rows x 3 columns]\n",
      "\n",
      "Filtered Data Summary (Date >= '2020-01-22'):\n",
      "            Date      Country  Cumulative_cases\n",
      "0     2020-01-22      Albania                 0\n",
      "1     2020-01-23      Albania                 0\n",
      "2     2020-01-24      Albania                 0\n",
      "3     2020-01-25      Albania                 0\n",
      "4     2020-01-26      Albania                 0\n",
      "...          ...          ...               ...\n",
      "27667 2020-01-31       Gambia                 0\n",
      "27668 2020-01-31  Netherlands                 0\n",
      "27669 2020-01-31        China               120\n",
      "27670 2020-03-31  Afghanistan               196\n",
      "27671 2020-03-31  Afghanistan               196\n",
      "\n",
      "[27672 rows x 3 columns]\n",
      "\n",
      "Filtered Data Summary (Country == 'Albania'):\n",
      "            Date  Country  Cumulative_cases\n",
      "0     2020-01-22  Albania                 0\n",
      "1     2020-01-23  Albania                 0\n",
      "2     2020-01-24  Albania                 0\n",
      "3     2020-01-25  Albania                 0\n",
      "4     2020-01-26  Albania                 0\n",
      "...          ...      ...               ...\n",
      "26735 2020-01-30  Albania                 0\n",
      "27243 2020-03-30  Albania               223\n",
      "27268 2020-03-30  Albania               223\n",
      "27524 2020-01-31  Albania                 0\n",
      "27658 2020-01-31  Albania                 0\n",
      "\n",
      "[483 rows x 3 columns]\n",
      "\n",
      "Date-wise Grouped Data Summary:\n",
      "Date\n",
      "2020-01-22        557\n",
      "2020-01-23        657\n",
      "2020-01-24        948\n",
      "2020-01-25       1448\n",
      "2020-01-26       2132\n",
      "               ...   \n",
      "2020-03-28     965413\n",
      "2020-03-29    1048913\n",
      "2020-03-30    1135554\n",
      "2020-03-31        392\n",
      "2020-04-01        478\n",
      "Name: Cumulative_cases, Length: 71, dtype: int64\n",
      "\n",
      "Country-wise Grouped Data Summary:\n",
      "Country\n",
      "Afghanistan     2972\n",
      "Albania        13923\n",
      "Algeria         8224\n",
      "Andorra         4822\n",
      "Angola            82\n",
      "               ...  \n",
      "Uzbekistan       890\n",
      "Venezuela       1161\n",
      "Vietnam         2718\n",
      "Zambia           159\n",
      "Zimbabwe          45\n",
      "Name: Cumulative_cases, Length: 174, dtype: int64\n",
      "\n",
      "Country and Date-wise Grouped Data Summary:\n",
      "Country      Date      \n",
      "Afghanistan  2020-01-22    0\n",
      "             2020-01-23    0\n",
      "             2020-01-24    0\n",
      "             2020-01-25    0\n",
      "             2020-01-26    0\n",
      "                          ..\n",
      "Zimbabwe     2020-03-26    3\n",
      "             2020-03-27    5\n",
      "             2020-03-28    7\n",
      "             2020-03-29    7\n",
      "             2020-03-30    7\n",
      "Name: Cumulative_cases, Length: 12008, dtype: int64\n",
      "\n",
      "Relation between Available Beds and Cumulative Deaths (Date-wise):\n",
      "            Available Beds/1000  Cumulative_death\n",
      "Date                                             \n",
      "2020-01-22             91.87355                17\n",
      "2020-01-23             92.12355                18\n",
      "2020-01-24             92.12355                26\n",
      "2020-01-25             92.12355                42\n",
      "2020-01-26             92.12355                56\n",
      "...                         ...               ...\n",
      "2020-03-28             92.12355             47992\n",
      "2020-03-29             92.12355             52906\n",
      "2020-03-30             91.37355             58360\n",
      "2020-03-31              0.21000                 8\n",
      "2020-04-01              0.21000                 8\n",
      "\n",
      "[71 rows x 2 columns]\n",
      "\n",
      "Relation between Available Beds and Cumulative Deaths (Country-wise):\n",
      "             Available Beds/1000  Cumulative_death\n",
      "Country                                           \n",
      "Afghanistan               14.910                66\n",
      "Albania                  300.150               532\n",
      "Algeria                   32.775               560\n",
      "Andorra                  129.375                54\n",
      "Angola                    27.600                 8\n",
      "...                          ...               ...\n",
      "Uzbekistan                 0.000                 7\n",
      "Venezuela                  0.000                 8\n",
      "Vietnam                    0.000                 0\n",
      "Zambia                     0.000                 0\n",
      "Zimbabwe                   0.000                 8\n",
      "\n",
      "[174 rows x 2 columns]\n",
      "\n",
      "Relation between Available Beds and Cumulative Deaths (Country and Date-wise):\n",
      "                        Available Beds/1000  Cumulative_death\n",
      "Country     Date                                             \n",
      "Afghanistan 2020-01-22                 0.21                 0\n",
      "            2020-01-23                 0.21                 0\n",
      "            2020-01-24                 0.21                 0\n",
      "            2020-01-25                 0.21                 0\n",
      "            2020-01-26                 0.21                 0\n",
      "...                                     ...               ...\n",
      "Zimbabwe    2020-03-26                 0.00                 1\n",
      "            2020-03-27                 0.00                 1\n",
      "            2020-03-28                 0.00                 1\n",
      "            2020-03-29                 0.00                 1\n",
      "            2020-03-30                 0.00                 1\n",
      "\n",
      "[12008 rows x 2 columns]\n",
      "Model Accuracy: 0.9484\n",
      "\n",
      "Column Names After Uniformity:\n",
      "Index(['date', 'state', 'country', 'cumulative_cases', 'cumulative_death',\n",
      "       'daily_cases', 'daily_death', 'min_temperature', 'max_temperature',\n",
      "       'wind_speed',\n",
      "       ...\n",
      "       'smokers', 'obesity', 'food_environment_index', 'exercise', 'diabetics',\n",
      "       'insufficient_sleep', 'traffic_volume', '65%_above_population',\n",
      "       'rural_population', 'cases'],\n",
      "      dtype='object', length=594)\n",
      "Model Accuracy: 0.9897\n",
      "Model Accuracy: 0.9629\n",
      "Model Accuracy: 0.9712\n",
      "          Date    State  Country  Cumulative_cases  Cumulative_death  \\\n",
      "0   22-01-2020  Unknown  Albania                 0                 0   \n",
      "1   23-01-2020  Unknown  Albania                 0                 0   \n",
      "2   24-01-2020  Unknown  Albania                 0                 0   \n",
      "3   25-01-2020  Unknown  Albania                 0                 0   \n",
      "4   26-01-2020  Unknown  Albania                 0                 0   \n",
      "..         ...      ...      ...               ...               ...   \n",
      "95  17-02-2020  Unknown  Albania                 0                 0   \n",
      "96  18-02-2020  Unknown  Albania                 0                 0   \n",
      "97  19-02-2020  Unknown  Albania                 0                 0   \n",
      "98  20-02-2020  Unknown  Albania                 0                 0   \n",
      "99  21-02-2020  Unknown  Albania                 0                 0   \n",
      "\n",
      "    Daily_cases  Daily_death  Min_temperature  Max_temperature  Wind_speed  \\\n",
      "0           0.0            0            -0.39            13.22         0.2   \n",
      "1           0.0            0             1.22            15.22         0.2   \n",
      "2           0.0            0             0.00            17.22         0.8   \n",
      "3           0.0            0             5.78            15.00         0.7   \n",
      "4           0.0            0             9.78            13.22         0.5   \n",
      "..          ...          ...              ...              ...         ...   \n",
      "95          0.0            0             3.61            18.00         0.7   \n",
      "96          0.0            0             4.00            16.78         0.8   \n",
      "97          0.0            0             7.50            17.78         0.4   \n",
      "98          0.0            0             8.22            14.50         4.1   \n",
      "99          0.0            0             0.61            14.61         0.8   \n",
      "\n",
      "    ...  Smokers  Obesity  Food Environment index Exercise  Diabetics  \\\n",
      "0   ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "1   ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "2   ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "3   ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "4   ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "..  ...      ...      ...                     ...      ...        ...   \n",
      "95  ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "96  ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "97  ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "98  ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "99  ...      NaN      NaN                     NaN      NaN        NaN   \n",
      "\n",
      "    Insufficient Sleep Traffic Volume  65% Above Population  Rural Population  \\\n",
      "0                  NaN            NaN                   NaN               NaN   \n",
      "1                  NaN            NaN                   NaN               NaN   \n",
      "2                  NaN            NaN                   NaN               NaN   \n",
      "3                  NaN            NaN                   NaN               NaN   \n",
      "4                  NaN            NaN                   NaN               NaN   \n",
      "..                 ...            ...                   ...               ...   \n",
      "95                 NaN            NaN                   NaN               NaN   \n",
      "96                 NaN            NaN                   NaN               NaN   \n",
      "97                 NaN            NaN                   NaN               NaN   \n",
      "98                 NaN            NaN                   NaN               NaN   \n",
      "99                 NaN            NaN                   NaN               NaN   \n",
      "\n",
      "    Cases  \n",
      "0     NaN  \n",
      "1     NaN  \n",
      "2     NaN  \n",
      "3     NaN  \n",
      "4     NaN  \n",
      "..    ...  \n",
      "95    NaN  \n",
      "96    NaN  \n",
      "97    NaN  \n",
      "98    NaN  \n",
      "99    NaN  \n",
      "\n",
      "[100 rows x 594 columns]\n",
      "Model Accuracy: 0.9836\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       Cumulative_cases   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     2.073\n",
      "Date:                Thu, 11 Apr 2024   Prob (F-statistic):              0.150\n",
      "Time:                        10:37:40   Log-Likelihood:            -2.7045e+05\n",
      "No. Observations:               27672   AIC:                         5.409e+05\n",
      "Df Residuals:                   27670   BIC:                         5.409e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    479.3721     25.881     18.522      0.000     428.644     530.100\n",
      "Wind_speed    -0.3869      0.269     -1.440      0.150      -0.914       0.140\n",
      "==============================================================================\n",
      "Omnibus:                    51842.657   Durbin-Watson:                   1.970\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         65395187.435\n",
      "Skew:                          14.556   Prob(JB):                         0.00\n",
      "Kurtosis:                     239.368   Cond. No.                         97.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Tasks Finished in 6.819131600001128 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import *\n",
    "from dtreeviz.trees import *\n",
    "import threading\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "def task1():\n",
    "    print(\"Task 1: Starting\")\n",
    "    #t1 = time.perf_counter()\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    \n",
    "    csv_file_path = './cleaned_data.csv'\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Handling outliers or incorrect values \n",
    "    df['Cumulative_cases'] = df['Cumulative_cases'].apply(lambda x: max(0, x))\n",
    "    print(df.head(100))\n",
    "    #time.sleep(2)  \n",
    "    #t2 = time.perf_counter()\n",
    "    #print(f'Task 1 Finished in {t2-t1} seconds')\n",
    "  #  time.sleep(2)\n",
    "    \n",
    "def task2():\n",
    "    print(\"Task 2: Starting\")\n",
    "    t1 = time.perf_counter()\n",
    "    import warnings\n",
    "    import pandas as pd\n",
    "    csv_file_path = './cleaned_data.csv'\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "        print(\"\\nColumn Names After Uniformity:\")\n",
    "        print(df.columns)\n",
    "    #time.sleep(2)\n",
    "    #t2 = time.perf_counter() \n",
    "    #print(f'Task 2 Finished in {t2-t1} seconds')\n",
    "  #  time.sleep(2)\n",
    "    \n",
    "def task3():\n",
    "    print(\"Task 3: Starting\")\n",
    "    t1 = time.perf_counter()\n",
    "    import warnings\n",
    "    import pandas as pd\n",
    "    csv_file_path = './merged_data.csv'\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import plotly.express as px\n",
    "    \n",
    "    target_col = ['Cumulative_death']\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X = df.drop(target_col, axis=1)  \n",
    "    y = df[target_col]                \n",
    "    \n",
    "    # Drop columns with NaN valuesz\n",
    "    X_no_nan = X.dropna(axis=1)\n",
    "    \n",
    "    # Convert 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
    "    \n",
    "    # Extract numeric features\n",
    "    numeric_columns = X_no_nan.select_dtypes(include=['float64', 'int64']).columns\n",
    "    X_numeric = X_no_nan[numeric_columns]\n",
    "    \n",
    "    # Use KFold for cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize a model \n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, test_index in kf.split(X_numeric):\n",
    "        X_train, X_test = X_numeric.iloc[train_index], X_numeric.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        # Fit the model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        # Print the model accuracy\n",
    "        score = model.score(X_test, y_test)\n",
    "        \n",
    "    import statsmodels.formula.api as smf\n",
    "    model = smf.ols('Cumulative_cases ~ Wind_speed', data=df)\n",
    "    results = model.fit()\n",
    "    print(results.summary())\n",
    "    #time.sleep(2)\n",
    "    #t2 = time.perf_counter()\n",
    "    #print(f'Task 3 Finished in {t2-t1} seconds')\n",
    "    #time.sleep(2)\n",
    "    \n",
    "def task4():\n",
    "    print(\"Task 4: Starting\")\n",
    "    t1 = time.perf_counter()\n",
    "    import warnings\n",
    "    import pandas as pd\n",
    "    import graphviz.backend as be\n",
    "    from IPython.display import Image, display_svg, SVG\n",
    "    from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "    import dtreeviz\n",
    "    \n",
    "    csv_file_path = './cleaned_data.csv'\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    target_col = 'cumulative_death'\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X = df.drop(target_col, axis=1)  \n",
    "    y = df[target_col]               \n",
    "    \n",
    "    # Drop columns with NaN values\n",
    "    X_no_nan = X.dropna(axis=1)\n",
    "    \n",
    "    # Convert 'Date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y')\n",
    "    \n",
    "    # Extract numeric features\n",
    "    numeric_columns = X_no_nan.select_dtypes(include=['float64', 'int64']).columns\n",
    "    X_numeric = X_no_nan[numeric_columns]\n",
    "    \n",
    "    # Use KFold for cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Initialize a Decision Tree model\n",
    "    model = DecisionTreeRegressor()\n",
    "    \n",
    "    # Perform k-fold cross-validation\n",
    "    for train_index, test_index in kf.split(X_numeric):\n",
    "        X_train, X_test = X_numeric.iloc[train_index], X_numeric.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "        # Fit the Decision Tree model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "        # Print the model accuracy\n",
    "        score = model.score(X_test, y_test)\n",
    "        print(f'Model Accuracy: {score:.4f}')\n",
    "\n",
    "    #time.sleep(2)\n",
    "    #t2 = time.perf_counter()\n",
    "    #print(f'Task 4 Finished in {t2-t1} seconds')\n",
    "    #time.sleep(2)\n",
    "    \n",
    "def task5():\n",
    "    print(\"Task 5: Starting\")\n",
    "    import requests\n",
    "    import time\n",
    "    import concurrent.futures\n",
    "    \n",
    "    img_urls = [\n",
    "        'https://images.unsplash.com/photo-1516117172878-fd2c41f4a759',\n",
    "        'https://images.unsplash.com/photo-1532009324734-20a7a5813719',\n",
    "        'https://images.unsplash.com/photo-1524429656589-6633a470097c',\n",
    "        ]\n",
    "    \n",
    "    t1 = time.perf_counter()\n",
    "    def download_image(img_url):\n",
    "        img_bytes = requests.get(img_url).content\n",
    "        img_name = img_url.split('/')[3]\n",
    "        img_name = f'{img_name}.jpg'\n",
    "        with open(img_name, 'wb') as img_file:\n",
    "            img_file.write(img_bytes)\n",
    "            #print(f'{img_name} was downloaded...')\n",
    "    \n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        executor.map(download_image, img_urls)\n",
    "\n",
    "   # time.sleep(2)\n",
    "    #t2 = time.perf_counter()\n",
    "    \n",
    "    #print(f'Task 5 Finished in {t2-t1} seconds')\n",
    "\n",
    "def task6():\n",
    "    print(\"Task 6: Starting\")\n",
    "    t1 = time.perf_counter()\n",
    "    import pandas as pd\n",
    "    csv_file_path = './merged_data.csv'\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Convert 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
    "    \n",
    "    # Filtering based Cumulative_cases > 0\n",
    "    filtered_data = df[(df['Cumulative_cases'] > 0)]\n",
    "    \n",
    "    # Displaying filtered data summary\n",
    "    print(\"Filtered Data Summary (Cumulative_cases > 0):\")\n",
    "    print(filtered_data[['Date', 'Country', 'Cumulative_cases']])\n",
    "    \n",
    "    # Additional filtering for date-wise and country-wise conditions\n",
    "    date_filter = (df['Date'] >= '2020-01-22')\n",
    "    country_filter = (df['Country'] == 'Albania')\n",
    "    \n",
    "    # Apply additional filters\n",
    "    filtered_data_date = df[date_filter]\n",
    "    filtered_data_country = df[country_filter]\n",
    "    \n",
    "    # Displaying filtered data summary for date-wise condition\n",
    "    print(\"\\nFiltered Data Summary (Date >= '2020-01-22'):\")\n",
    "    print(filtered_data_date[['Date', 'Country', 'Cumulative_cases']])\n",
    "    \n",
    "    # Displaying filtered data summary for country-wise condition\n",
    "    print(\"\\nFiltered Data Summary (Country == 'Albania'):\")\n",
    "    print(filtered_data_country[['Date', 'Country', 'Cumulative_cases']])\n",
    "    \n",
    "    # Grouping by 'Date' and finding the sum of 'Cumulative_cases'\n",
    "    grouped_data_datewise = df.groupby('Date')['Cumulative_cases'].sum()\n",
    "    \n",
    "    # Displaying date-wise grouped data summary\n",
    "    print(\"\\nDate-wise Grouped Data Summary:\")\n",
    "    print(grouped_data_datewise)\n",
    "    \n",
    "    # Grouping by 'Country' and finding the sum of 'Cumulative_cases'\n",
    "    grouped_data_countrywise = df.groupby('Country')['Cumulative_cases'].sum()\n",
    "    \n",
    "    # Displaying country-wise grouped data summary\n",
    "    print(\"\\nCountry-wise Grouped Data Summary:\")\n",
    "    print(grouped_data_countrywise)\n",
    "    \n",
    "    # Grouping by 'Country' and 'Date' and finding the sum of 'Cumulative_cases'\n",
    "    grouped_data_country_datewise = df.groupby(['Country', 'Date'])['Cumulative_cases'].sum()\n",
    "    \n",
    "    # Displaying country and date-wise grouped data summary\n",
    "    print(\"\\nCountry and Date-wise Grouped Data Summary:\")\n",
    "    print(grouped_data_country_datewise)\n",
    "    \n",
    "    # Relation between 'Available Beds' and 'Cumulative Deaths' for each grouping\n",
    "    relation_data = df.groupby('Date')[['Available Beds/1000', 'Cumulative_death']].sum()\n",
    "    print(\"\\nRelation between Available Beds and Cumulative Deaths (Date-wise):\")\n",
    "    print(relation_data)\n",
    "    \n",
    "    relation_data = df.groupby('Country')[['Available Beds/1000', 'Cumulative_death']].sum()\n",
    "    print(\"\\nRelation between Available Beds and Cumulative Deaths (Country-wise):\")\n",
    "    print(relation_data)\n",
    "    \n",
    "    relation_data = df.groupby(['Country', 'Date'])[['Available Beds/1000', 'Cumulative_death']].sum()\n",
    "    print(\"\\nRelation between Available Beds and Cumulative Deaths (Country and Date-wise):\")\n",
    "    print(relation_data)\n",
    "    #time.sleep(2)\n",
    "    #t2 = time.perf_counter()\n",
    "    #print(f'Task 6 Finished in {t2-t1} seconds')\n",
    "    \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "    # Submit each task to the executor\n",
    "    executor.submit(task1)\n",
    "    executor.submit(task2)\n",
    "    executor.submit(task3)\n",
    "    executor.submit(task4)\n",
    "    executor.submit(task5)\n",
    "    executor.submit(task6)\n",
    "\n",
    "t2 = time.perf_counter()\n",
    "print(f'Tasks Finished in {t2-t1} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
